{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>ABSTRACT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20973</td>\n",
       "      <td>Closed-form Marginal Likelihood in Gamma-Poiss...</td>\n",
       "      <td>We present novel understandings of the Gamma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20974</td>\n",
       "      <td>Laboratory mid-IR spectra of equilibrated and ...</td>\n",
       "      <td>Meteorites contain minerals from Solar Syste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20975</td>\n",
       "      <td>Case For Static AMSDU Aggregation in WLANs</td>\n",
       "      <td>Frame aggregation is a mechanism by which mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20976</td>\n",
       "      <td>The $Gaia$-ESO Survey: the inner disk intermed...</td>\n",
       "      <td>Milky Way open clusters are very diverse in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20977</td>\n",
       "      <td>Witness-Functions versus Interpretation-Functi...</td>\n",
       "      <td>Proving that a cryptographic protocol is cor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8984</th>\n",
       "      <td>29957</td>\n",
       "      <td>Supporting mixed-datatype matrix multiplicatio...</td>\n",
       "      <td>We approach the problem of implementing mixe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8985</th>\n",
       "      <td>29958</td>\n",
       "      <td>An axiomatic basis for Blackwell optimality</td>\n",
       "      <td>In the theory of Markov decision processes (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8986</th>\n",
       "      <td>29959</td>\n",
       "      <td>GeneVis - An interactive visualization tool fo...</td>\n",
       "      <td>GeneVis is a web-based tool to visualize com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8987</th>\n",
       "      <td>29960</td>\n",
       "      <td>Quantifying the causal effect of speed cameras...</td>\n",
       "      <td>This paper quantifies the effect of speed ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8988</th>\n",
       "      <td>29961</td>\n",
       "      <td>Cube-magic labelings of grids</td>\n",
       "      <td>We show that the vertices and edges of a $d$...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8989 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                              TITLE  \\\n",
       "0     20973  Closed-form Marginal Likelihood in Gamma-Poiss...   \n",
       "1     20974  Laboratory mid-IR spectra of equilibrated and ...   \n",
       "2     20975         Case For Static AMSDU Aggregation in WLANs   \n",
       "3     20976  The $Gaia$-ESO Survey: the inner disk intermed...   \n",
       "4     20977  Witness-Functions versus Interpretation-Functi...   \n",
       "...     ...                                                ...   \n",
       "8984  29957  Supporting mixed-datatype matrix multiplicatio...   \n",
       "8985  29958        An axiomatic basis for Blackwell optimality   \n",
       "8986  29959  GeneVis - An interactive visualization tool fo...   \n",
       "8987  29960  Quantifying the causal effect of speed cameras...   \n",
       "8988  29961                      Cube-magic labelings of grids   \n",
       "\n",
       "                                               ABSTRACT  \n",
       "0       We present novel understandings of the Gamma...  \n",
       "1       Meteorites contain minerals from Solar Syste...  \n",
       "2       Frame aggregation is a mechanism by which mu...  \n",
       "3       Milky Way open clusters are very diverse in ...  \n",
       "4       Proving that a cryptographic protocol is cor...  \n",
       "...                                                 ...  \n",
       "8984    We approach the problem of implementing mixe...  \n",
       "8985    In the theory of Markov decision processes (...  \n",
       "8986    GeneVis is a web-based tool to visualize com...  \n",
       "8987    This paper quantifies the effect of speed ca...  \n",
       "8988    We show that the vertices and edges of a $d$...  \n",
       "\n",
       "[8989 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "data = pd.read_csv('test.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import matutils, models\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract=data['ABSTRACT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         We present novel understandings of the Gamma...\n",
       "1         Meteorites contain minerals from Solar Syste...\n",
       "2         Frame aggregation is a mechanism by which mu...\n",
       "3         Milky Way open clusters are very diverse in ...\n",
       "4         Proving that a cryptographic protocol is cor...\n",
       "                              ...                        \n",
       "8984      We approach the problem of implementing mixe...\n",
       "8985      In the theory of Markov decision processes (...\n",
       "8986      GeneVis is a web-based tool to visualize com...\n",
       "8987      This paper quantifies the effect of speed ca...\n",
       "8988      We show that the vertices and edges of a $d$...\n",
       "Name: ABSTRACT, Length: 8989, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "data['ABSTRACT'] = data['ABSTRACT'].apply(lambda x: re.sub(r'[^\\w\\s]','', str(x)))\n",
    "data['ABSTRACT'] = data['ABSTRACT'].apply(lambda x: re.sub(r'[0-9]','', str(x)))\n",
    "data['ABSTRACT'] = data['ABSTRACT'].apply(lambda x: re.sub('\\n','', str(x)))\n",
    "data['ABSTRACT'] = data['ABSTRACT'].apply(lambda x: re.sub('\\t','', str(x)))\n",
    "data['ABSTRACT'] = data['ABSTRACT'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\PYTHON39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "data_cv = cv.fit_transform(data.ABSTRACT)\n",
    "dt = pd.DataFrame(data_cv.toarray()).iloc[:len(data)]  \n",
    "dt.columns = cv.get_feature_names()\n",
    "dt.index = data.TITLE\n",
    "document_term_matrix = dt.T\n",
    "document_term_matrix.columns = ['ABSTRACT '+str(i+1) for i in range(len(data))]\n",
    "document_term_matrix['total_count'] = document_term_matrix.sum(axis=1)\n",
    "\n",
    "document_term_matrix = document_term_matrix.sort_values(by ='total_count',ascending=False)[:2000] \n",
    "\n",
    "#print(document_term_matrix.drop(columns=['total_count']).head(10))\n",
    "most_common = document_term_matrix.index\n",
    "document_term_matrix = document_term_matrix.drop(columns=['total_count'])\n",
    "dtm1 = pd.DataFrame(document_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABSTRACT 1</th>\n",
       "      <th>ABSTRACT 2</th>\n",
       "      <th>ABSTRACT 3</th>\n",
       "      <th>ABSTRACT 4</th>\n",
       "      <th>ABSTRACT 5</th>\n",
       "      <th>ABSTRACT 6</th>\n",
       "      <th>ABSTRACT 7</th>\n",
       "      <th>ABSTRACT 8</th>\n",
       "      <th>ABSTRACT 9</th>\n",
       "      <th>ABSTRACT 10</th>\n",
       "      <th>...</th>\n",
       "      <th>ABSTRACT 8980</th>\n",
       "      <th>ABSTRACT 8981</th>\n",
       "      <th>ABSTRACT 8982</th>\n",
       "      <th>ABSTRACT 8983</th>\n",
       "      <th>ABSTRACT 8984</th>\n",
       "      <th>ABSTRACT 8985</th>\n",
       "      <th>ABSTRACT 8986</th>\n",
       "      <th>ABSTRACT 8987</th>\n",
       "      <th>ABSTRACT 8988</th>\n",
       "      <th>ABSTRACT 8989</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>using</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paper</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>industry</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arbitrarily</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rnns</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interplay</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dependency</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 8989 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ABSTRACT 1  ABSTRACT 2  ABSTRACT 3  ABSTRACT 4  ABSTRACT 5  \\\n",
       "model                 2           0           1           0           0   \n",
       "data                  1           0           0           1           0   \n",
       "using                 0           0           0           1           0   \n",
       "paper                 0           0           0           0           1   \n",
       "results               0           0           0           0           0   \n",
       "...                 ...         ...         ...         ...         ...   \n",
       "industry              0           0           0           0           0   \n",
       "arbitrarily           0           0           0           0           0   \n",
       "rnns                  0           0           0           0           0   \n",
       "interplay             0           0           0           0           0   \n",
       "dependency            0           0           0           0           0   \n",
       "\n",
       "             ABSTRACT 6  ABSTRACT 7  ABSTRACT 8  ABSTRACT 9  ABSTRACT 10  ...  \\\n",
       "model                 2           1           0           0            0  ...   \n",
       "data                  1           0           5           0            0  ...   \n",
       "using                 0           0           0           1            0  ...   \n",
       "paper                 1           0           0           1            0  ...   \n",
       "results               0           2           1           1            1  ...   \n",
       "...                 ...         ...         ...         ...          ...  ...   \n",
       "industry              0           0           0           0            0  ...   \n",
       "arbitrarily           0           0           0           0            0  ...   \n",
       "rnns                  0           0           0           0            0  ...   \n",
       "interplay             0           0           0           0            0  ...   \n",
       "dependency            0           0           0           0            0  ...   \n",
       "\n",
       "             ABSTRACT 8980  ABSTRACT 8981  ABSTRACT 8982  ABSTRACT 8983  \\\n",
       "model                    0              2              0              0   \n",
       "data                     0              0              0              0   \n",
       "using                    0              0              1              1   \n",
       "paper                    0              0              1              0   \n",
       "results                  0              0              0              0   \n",
       "...                    ...            ...            ...            ...   \n",
       "industry                 0              0              0              0   \n",
       "arbitrarily              0              0              0              0   \n",
       "rnns                     0              0              0              0   \n",
       "interplay                0              0              0              0   \n",
       "dependency               0              0              0              0   \n",
       "\n",
       "             ABSTRACT 8984  ABSTRACT 8985  ABSTRACT 8986  ABSTRACT 8987  \\\n",
       "model                    0              0              0              0   \n",
       "data                     0              0              0              3   \n",
       "using                    0              0              0              1   \n",
       "paper                    1              0              1              0   \n",
       "results                  1              1              0              0   \n",
       "...                    ...            ...            ...            ...   \n",
       "industry                 0              0              0              0   \n",
       "arbitrarily              0              0              0              0   \n",
       "rnns                     0              0              0              0   \n",
       "interplay                0              0              0              0   \n",
       "dependency               0              0              0              0   \n",
       "\n",
       "             ABSTRACT 8988  ABSTRACT 8989  \n",
       "model                    0              0  \n",
       "data                     0              0  \n",
       "using                    1              0  \n",
       "paper                    1              0  \n",
       "results                  1              0  \n",
       "...                    ...            ...  \n",
       "industry                 0              0  \n",
       "arbitrarily              0              0  \n",
       "rnns                     0              0  \n",
       "interplay                0              0  \n",
       "dependency               0              0  \n",
       "\n",
       "[2000 rows x 8989 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "from gensim import matutils, models\n",
    "sparse_counts = scipy.sparse.csr_matrix(dtm1)\n",
    "corpus = matutils.Sparse2Corpus(sparse_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'model',\n",
       " 1: 'data',\n",
       " 2: 'using',\n",
       " 3: 'paper',\n",
       " 4: 'results',\n",
       " 5: 'method',\n",
       " 6: 'problem',\n",
       " 7: 'learning',\n",
       " 8: 'based',\n",
       " 9: 'models',\n",
       " 10: 'new',\n",
       " 11: 'approach',\n",
       " 12: 'study',\n",
       " 13: 'network',\n",
       " 14: 'time',\n",
       " 15: 'algorithm',\n",
       " 16: 'number',\n",
       " 17: 'used',\n",
       " 18: 'methods',\n",
       " 19: 'proposed',\n",
       " 20: 'systems',\n",
       " 21: 'networks',\n",
       " 22: 'different',\n",
       " 23: 'propose',\n",
       " 24: 'present',\n",
       " 25: 'analysis',\n",
       " 26: 'use',\n",
       " 27: 'function',\n",
       " 28: 'work',\n",
       " 29: 'performance',\n",
       " 30: 'set',\n",
       " 31: 'information',\n",
       " 32: 'space',\n",
       " 33: 'large',\n",
       " 34: 'neural',\n",
       " 35: 'algorithms',\n",
       " 36: 'order',\n",
       " 37: 'provide',\n",
       " 38: 'structure',\n",
       " 39: 'case',\n",
       " 40: 'given',\n",
       " 41: 'field',\n",
       " 42: 'energy',\n",
       " 43: 'state',\n",
       " 44: 'properties',\n",
       " 45: 'deep',\n",
       " 46: 'theory',\n",
       " 47: 'framework',\n",
       " 48: 'high',\n",
       " 49: 'distribution',\n",
       " 50: 'linear',\n",
       " 51: 'demonstrate',\n",
       " 52: 'process',\n",
       " 53: 'problems',\n",
       " 54: 'prove',\n",
       " 55: 'result',\n",
       " 56: 'features',\n",
       " 57: 'parameters',\n",
       " 58: 'novel',\n",
       " 59: 'general',\n",
       " 60: 'rate',\n",
       " 61: 'training',\n",
       " 62: 'quantum',\n",
       " 63: 'functions',\n",
       " 64: 'applications',\n",
       " 65: 'phase',\n",
       " 66: 'consider',\n",
       " 67: 'ofthe',\n",
       " 68: 'graph',\n",
       " 69: 'dynamics',\n",
       " 70: 'control',\n",
       " 71: 'particular',\n",
       " 72: 'experiments',\n",
       " 73: 'optimal',\n",
       " 74: 'class',\n",
       " 75: 'terms',\n",
       " 76: 'solution',\n",
       " 77: 'recent',\n",
       " 78: 'random',\n",
       " 79: 'known',\n",
       " 80: 'size',\n",
       " 81: 'point',\n",
       " 82: 'local',\n",
       " 83: 'states',\n",
       " 84: 'complex',\n",
       " 85: 'group',\n",
       " 86: 'accuracy',\n",
       " 87: 'design',\n",
       " 88: 'conditions',\n",
       " 89: 'real',\n",
       " 90: 'multiple',\n",
       " 91: 'simple',\n",
       " 92: 'power',\n",
       " 93: 'obtained',\n",
       " 94: 'techniques',\n",
       " 95: 'small',\n",
       " 96: 'magnetic',\n",
       " 97: 'optimization',\n",
       " 98: 'introduce',\n",
       " 99: 'important',\n",
       " 100: 'approaches',\n",
       " 101: 'solutions',\n",
       " 102: 'compared',\n",
       " 103: 'matrix',\n",
       " 104: 'numerical',\n",
       " 105: 'classification',\n",
       " 106: 'tasks',\n",
       " 107: 'finite',\n",
       " 108: 'range',\n",
       " 109: 'existing',\n",
       " 110: 'shown',\n",
       " 111: 'potential',\n",
       " 112: 'machine',\n",
       " 113: 'test',\n",
       " 114: 'various',\n",
       " 115: 'form',\n",
       " 116: 'observed',\n",
       " 117: 'image',\n",
       " 118: 'density',\n",
       " 119: 'surface',\n",
       " 120: 'allows',\n",
       " 121: 'datasets',\n",
       " 122: 'task',\n",
       " 123: 'single',\n",
       " 124: 'finally',\n",
       " 125: 'detection',\n",
       " 126: 'low',\n",
       " 127: 'stochastic',\n",
       " 128: 'research',\n",
       " 129: 'equation',\n",
       " 130: 'possible',\n",
       " 131: 'equations',\n",
       " 132: 'obtain',\n",
       " 133: 'parameter',\n",
       " 134: 'behavior',\n",
       " 135: 'type',\n",
       " 136: 'efficient',\n",
       " 137: 'simulations',\n",
       " 138: 'studies',\n",
       " 139: 'provides',\n",
       " 140: 'estimation',\n",
       " 141: 'way',\n",
       " 142: 'previous',\n",
       " 143: 'effects',\n",
       " 144: 'level',\n",
       " 145: 'including',\n",
       " 146: 'investigate',\n",
       " 147: 'mass',\n",
       " 148: 'domain',\n",
       " 149: 'computational',\n",
       " 150: 'input',\n",
       " 151: 'error',\n",
       " 152: 'probability',\n",
       " 153: 'standard',\n",
       " 154: 'effect',\n",
       " 155: 'current',\n",
       " 156: 'sample',\n",
       " 157: 'bound',\n",
       " 158: 'experimental',\n",
       " 159: 'second',\n",
       " 160: 'complexity',\n",
       " 161: 'nonlinear',\n",
       " 162: 'develop',\n",
       " 163: 'better',\n",
       " 164: 'value',\n",
       " 165: 'similar',\n",
       " 166: 'knowledge',\n",
       " 167: 'observations',\n",
       " 168: 'technique',\n",
       " 169: 'applied',\n",
       " 170: 'flow',\n",
       " 171: 'images',\n",
       " 172: 'dataset',\n",
       " 173: 'values',\n",
       " 174: 'prediction',\n",
       " 175: 'sets',\n",
       " 176: 'examples',\n",
       " 177: 'cases',\n",
       " 178: 'does',\n",
       " 179: 'simulation',\n",
       " 180: 'related',\n",
       " 181: 'cost',\n",
       " 182: 'main',\n",
       " 183: 'feature',\n",
       " 184: 'statistical',\n",
       " 185: 'effective',\n",
       " 186: 'representation',\n",
       " 187: 'spin',\n",
       " 188: 'points',\n",
       " 189: 'noise',\n",
       " 190: 'users',\n",
       " 191: 'source',\n",
       " 192: 'available',\n",
       " 193: 'temperature',\n",
       " 194: 'lower',\n",
       " 195: 'certain',\n",
       " 196: 'theoretical',\n",
       " 197: 'application',\n",
       " 198: 'classical',\n",
       " 199: 'associated',\n",
       " 200: 'groups',\n",
       " 201: 'convergence',\n",
       " 202: 'graphs',\n",
       " 203: 'human',\n",
       " 204: 'presented',\n",
       " 205: 'developed',\n",
       " 206: 'derive',\n",
       " 207: 'measurements',\n",
       " 208: 'times',\n",
       " 209: 'spectral',\n",
       " 210: 'measure',\n",
       " 211: 'best',\n",
       " 212: 'bounds',\n",
       " 213: 'fields',\n",
       " 214: 'scheme',\n",
       " 215: 'robust',\n",
       " 216: 'recently',\n",
       " 217: 'gradient',\n",
       " 218: 'approximation',\n",
       " 219: 'discuss',\n",
       " 220: 'strong',\n",
       " 221: 'higher',\n",
       " 222: 'context',\n",
       " 223: 'scale',\n",
       " 224: 'modeling',\n",
       " 225: 'interaction',\n",
       " 226: 'key',\n",
       " 227: 'addition',\n",
       " 228: 'structures',\n",
       " 229: 'distributions',\n",
       " 230: 'user',\n",
       " 231: 'samples',\n",
       " 232: 'boundary',\n",
       " 233: 'topological',\n",
       " 234: 'global',\n",
       " 235: 'target',\n",
       " 236: 'significant',\n",
       " 237: 'series',\n",
       " 238: 'able',\n",
       " 239: 'example',\n",
       " 240: 'inference',\n",
       " 241: 'apply',\n",
       " 242: 'transition',\n",
       " 243: 'social',\n",
       " 244: 'called',\n",
       " 245: 'types',\n",
       " 246: 'processes',\n",
       " 247: 'studied',\n",
       " 248: 'corresponding',\n",
       " 249: 'inthe',\n",
       " 250: 'estimate',\n",
       " 251: 'search',\n",
       " 252: 'critical',\n",
       " 253: 'regression',\n",
       " 254: 'quality',\n",
       " 255: 'natural',\n",
       " 256: 'defined',\n",
       " 257: 'variables',\n",
       " 258: 'light',\n",
       " 259: 'dynamic',\n",
       " 260: 'average',\n",
       " 261: 'stateoftheart',\n",
       " 262: 'improve',\n",
       " 263: 'theorem',\n",
       " 264: 'loss',\n",
       " 265: 'mean',\n",
       " 266: 'achieve',\n",
       " 267: 'learn',\n",
       " 268: 'vector',\n",
       " 269: 'furthermore',\n",
       " 270: 'common',\n",
       " 271: 'limit',\n",
       " 272: 'motion',\n",
       " 273: 'shows',\n",
       " 274: 'setting',\n",
       " 275: 'signal',\n",
       " 276: 'online',\n",
       " 277: 'open',\n",
       " 278: 'distance',\n",
       " 279: 'need',\n",
       " 280: 'distributed',\n",
       " 281: 'derived',\n",
       " 282: 'spatial',\n",
       " 283: 'classes',\n",
       " 284: 'spectrum',\n",
       " 285: 'evolution',\n",
       " 286: 'code',\n",
       " 287: 'objects',\n",
       " 288: 'efficiency',\n",
       " 289: 'sampling',\n",
       " 290: 'language',\n",
       " 291: 'considered',\n",
       " 292: 'address',\n",
       " 293: 'estimates',\n",
       " 294: 'generated',\n",
       " 295: 'specific',\n",
       " 296: 'gaussian',\n",
       " 297: 'spaces',\n",
       " 298: 'make',\n",
       " 299: 'variety',\n",
       " 300: 'wave',\n",
       " 301: 'dimension',\n",
       " 302: 'role',\n",
       " 303: 'future',\n",
       " 304: 'degree',\n",
       " 305: 'selection',\n",
       " 306: 'interactions',\n",
       " 307: 'convex',\n",
       " 308: 'perform',\n",
       " 309: 'respect',\n",
       " 310: 'impact',\n",
       " 311: 'patterns',\n",
       " 312: 'fixed',\n",
       " 313: 'constant',\n",
       " 314: 'constraints',\n",
       " 315: 'components',\n",
       " 316: 'sequence',\n",
       " 317: 'empirical',\n",
       " 318: 'condition',\n",
       " 319: 'good',\n",
       " 320: 'presence',\n",
       " 321: 'map',\n",
       " 322: 'continuous',\n",
       " 323: 'identify',\n",
       " 324: 'analyze',\n",
       " 325: 'trained',\n",
       " 326: 'like',\n",
       " 327: 'significantly',\n",
       " 328: 'environment',\n",
       " 329: 'understanding',\n",
       " 330: 'optical',\n",
       " 331: 'sources',\n",
       " 332: 'existence',\n",
       " 333: 'architecture',\n",
       " 334: 'solve',\n",
       " 335: 'independent',\n",
       " 336: 'free',\n",
       " 337: 'literature',\n",
       " 338: 'initial',\n",
       " 339: 'nodes',\n",
       " 340: 'formation',\n",
       " 341: 'al',\n",
       " 342: 'representations',\n",
       " 343: 'article',\n",
       " 344: 'et',\n",
       " 345: 'introduced',\n",
       " 346: 'layer',\n",
       " 347: 'physical',\n",
       " 348: 'compare',\n",
       " 349: 'positive',\n",
       " 350: 'bayesian',\n",
       " 351: 'prior',\n",
       " 352: 'maximum',\n",
       " 353: 'accurate',\n",
       " 354: 'construct',\n",
       " 355: 'cluster',\n",
       " 356: 'rates',\n",
       " 357: 'memory',\n",
       " 358: 'highly',\n",
       " 359: 'frequency',\n",
       " 360: 'clustering',\n",
       " 361: 'total',\n",
       " 362: 'polynomial',\n",
       " 363: 'evaluation',\n",
       " 364: 'strategy',\n",
       " 365: 'changes',\n",
       " 366: 'property',\n",
       " 367: 'matter',\n",
       " 368: 'support',\n",
       " 369: 'line',\n",
       " 370: 'resulting',\n",
       " 371: 'sparse',\n",
       " 372: 'long',\n",
       " 373: 'metric',\n",
       " 374: 'evaluate',\n",
       " 375: 'change',\n",
       " 376: 'growth',\n",
       " 377: 'computing',\n",
       " 378: 'focus',\n",
       " 379: 'mechanism',\n",
       " 380: 'object',\n",
       " 381: 'discrete',\n",
       " 382: 'policy',\n",
       " 383: 'factor',\n",
       " 384: 'step',\n",
       " 385: 'generate',\n",
       " 386: 'allow',\n",
       " 387: 'gas',\n",
       " 388: 'uses',\n",
       " 389: 'fast',\n",
       " 390: 'leads',\n",
       " 391: 'direct',\n",
       " 392: 'latent',\n",
       " 393: 'arbitrary',\n",
       " 394: 'limited',\n",
       " 395: 'procedure',\n",
       " 396: 'provided',\n",
       " 397: 'gap',\n",
       " 398: 'upper',\n",
       " 399: 'realworld',\n",
       " 400: 'means',\n",
       " 401: 'coupling',\n",
       " 402: 'nature',\n",
       " 403: 'consistent',\n",
       " 404: 'fundamental',\n",
       " 405: 'objective',\n",
       " 406: 'relative',\n",
       " 407: 'regions',\n",
       " 408: 'version',\n",
       " 409: 'requires',\n",
       " 410: 'wide',\n",
       " 411: 'ratio',\n",
       " 412: 'family',\n",
       " 413: 'estimator',\n",
       " 414: 'useful',\n",
       " 415: 'increase',\n",
       " 416: 'dark',\n",
       " 417: 'region',\n",
       " 418: 'kernel',\n",
       " 419: 'processing',\n",
       " 420: 'clusters',\n",
       " 421: 'geometry',\n",
       " 422: 'component',\n",
       " 423: 'proof',\n",
       " 424: 'close',\n",
       " 425: 'reduce',\n",
       " 426: 'stability',\n",
       " 427: 'special',\n",
       " 428: 'explicit',\n",
       " 429: 'transfer',\n",
       " 430: 'let',\n",
       " 431: 'generation',\n",
       " 432: 'goal',\n",
       " 433: 'development',\n",
       " 434: 'devices',\n",
       " 435: 'stable',\n",
       " 436: 'correlation',\n",
       " 437: 'lead',\n",
       " 438: 'weak',\n",
       " 439: 'velocity',\n",
       " 440: 'functional',\n",
       " 441: 'tool',\n",
       " 442: 'temporal',\n",
       " 443: 'additional',\n",
       " 444: 'explore',\n",
       " 445: 'length',\n",
       " 446: 'larger',\n",
       " 447: 'increasing',\n",
       " 448: 'regime',\n",
       " 449: 'reduction',\n",
       " 450: 'expected',\n",
       " 451: 'computation',\n",
       " 452: 'relevant',\n",
       " 453: 'years',\n",
       " 454: 'geometric',\n",
       " 455: 'galaxies',\n",
       " 456: 'adversarial',\n",
       " 457: 'communication',\n",
       " 458: 'symmetry',\n",
       " 459: 'performed',\n",
       " 460: 'compute',\n",
       " 461: 'required',\n",
       " 462: 'response',\n",
       " 463: 'underlying',\n",
       " 464: 'convolutional',\n",
       " 465: 'statistics',\n",
       " 466: 'original',\n",
       " 467: 'fact',\n",
       " 468: 'layers',\n",
       " 469: 'risk',\n",
       " 470: 'domains',\n",
       " 471: 'spectra',\n",
       " 472: 'implementation',\n",
       " 473: 'lattice',\n",
       " 474: 'algebra',\n",
       " 475: 'directly',\n",
       " 476: 'operator',\n",
       " 477: 'achieved',\n",
       " 478: 'generalized',\n",
       " 479: 'extend',\n",
       " 480: 'binary',\n",
       " 481: 'software',\n",
       " 482: 'question',\n",
       " 483: 'attention',\n",
       " 484: 'challenging',\n",
       " 485: 'determine',\n",
       " 486: 'bounded',\n",
       " 487: 'asymptotic',\n",
       " 488: 'basis',\n",
       " 489: 'comparison',\n",
       " 490: 'ability',\n",
       " 491: 'generalization',\n",
       " 492: 'area',\n",
       " 493: 'tothe',\n",
       " 494: 'require',\n",
       " 495: 'electron',\n",
       " 496: 'designed',\n",
       " 497: 'illustrate',\n",
       " 498: 'approximate',\n",
       " 499: 'presents',\n",
       " 500: 'account',\n",
       " 501: 'fully',\n",
       " 502: 'previously',\n",
       " 503: 'molecular',\n",
       " 504: 'specifically',\n",
       " 505: 'exact',\n",
       " 506: 'suitable',\n",
       " 507: 'thermal',\n",
       " 508: 'tools',\n",
       " 509: 'levels',\n",
       " 510: 'contrast',\n",
       " 511: 'making',\n",
       " 512: 'popular',\n",
       " 513: 'visual',\n",
       " 514: 'capture',\n",
       " 515: 'assumptions',\n",
       " 516: 'effectiveness',\n",
       " 517: 'recognition',\n",
       " 518: 'define',\n",
       " 519: 'zero',\n",
       " 520: 'rank',\n",
       " 521: 'stars',\n",
       " 522: 'numbers',\n",
       " 523: 'product',\n",
       " 524: 'generative',\n",
       " 525: 'connected',\n",
       " 526: 'dimensional',\n",
       " 527: 'transport',\n",
       " 528: 'extended',\n",
       " 529: 'establish',\n",
       " 530: 'evidence',\n",
       " 531: 'individual',\n",
       " 532: 'described',\n",
       " 533: 'hand',\n",
       " 534: 'dynamical',\n",
       " 535: 'tensor',\n",
       " 536: 'uncertainty',\n",
       " 537: 'onthe',\n",
       " 538: 'predictions',\n",
       " 539: 'particle',\n",
       " 540: 'maps',\n",
       " 541: 'agents',\n",
       " 542: 'learned',\n",
       " 543: 'computer',\n",
       " 544: 'practical',\n",
       " 545: 'scales',\n",
       " 546: 'measures',\n",
       " 547: 'particles',\n",
       " 548: 'shape',\n",
       " 549: 'predict',\n",
       " 550: 'compact',\n",
       " 551: 'notion',\n",
       " 552: 'action',\n",
       " 553: 'discussed',\n",
       " 554: 'structural',\n",
       " 555: 'complete',\n",
       " 556: 'signals',\n",
       " 557: 'makes',\n",
       " 558: 'variable',\n",
       " 559: 'challenge',\n",
       " 560: 'active',\n",
       " 561: 'ii',\n",
       " 562: 'edge',\n",
       " 563: 'influence',\n",
       " 564: 'activity',\n",
       " 565: 'star',\n",
       " 566: 'factors',\n",
       " 567: 'works',\n",
       " 568: 'dependence',\n",
       " 569: 'game',\n",
       " 570: 'efficiently',\n",
       " 571: 'respectively',\n",
       " 572: 'term',\n",
       " 573: 'resolution',\n",
       " 574: 'emission',\n",
       " 575: 'chain',\n",
       " 576: 'enables',\n",
       " 577: 'traditional',\n",
       " 578: 'speed',\n",
       " 579: 'core',\n",
       " 580: 'improved',\n",
       " 581: 'construction',\n",
       " 582: 'materials',\n",
       " 583: 'measured',\n",
       " 584: 'operators',\n",
       " 585: 'population',\n",
       " 586: 'following',\n",
       " 587: 'finding',\n",
       " 588: 'channel',\n",
       " 589: 'electronic',\n",
       " 590: 'report',\n",
       " 591: 'investigated',\n",
       " 592: 'depends',\n",
       " 593: 'faster',\n",
       " 594: 'differential',\n",
       " 595: 'unknown',\n",
       " 596: 'instead',\n",
       " 597: 'sufficient',\n",
       " 598: 'band',\n",
       " 599: 'difficult',\n",
       " 600: 'induced',\n",
       " 601: 'largescale',\n",
       " 602: 'central',\n",
       " 603: 'phases',\n",
       " 604: 'necessary',\n",
       " 605: 'scenarios',\n",
       " 606: 'ground',\n",
       " 607: 'widely',\n",
       " 608: 'modes',\n",
       " 609: 'output',\n",
       " 610: 'elements',\n",
       " 611: 'combination',\n",
       " 612: 'measurement',\n",
       " 613: 'outperforms',\n",
       " 614: 'relation',\n",
       " 615: 'community',\n",
       " 616: 'testing',\n",
       " 617: 'smooth',\n",
       " 618: 'sum',\n",
       " 619: 'waves',\n",
       " 620: 'include',\n",
       " 621: 'monte',\n",
       " 622: 'access',\n",
       " 623: 'strongly',\n",
       " 624: 'subset',\n",
       " 625: 'assumption',\n",
       " 626: 'xray',\n",
       " 627: 'synthetic',\n",
       " 628: 'word',\n",
       " 629: 'major',\n",
       " 630: 'magnitude',\n",
       " 631: 'markov',\n",
       " 632: 'events',\n",
       " 633: 'alternative',\n",
       " 634: 'index',\n",
       " 635: 'normal',\n",
       " 636: 'produce',\n",
       " 637: 'demonstrated',\n",
       " 638: 'equivalent',\n",
       " 639: 'minimum',\n",
       " 640: 'reduced',\n",
       " 641: 'physics',\n",
       " 642: 'benchmark',\n",
       " 643: 'matrices',\n",
       " 644: 'scattering',\n",
       " 645: 'text',\n",
       " 646: 'carlo',\n",
       " 647: 'observe',\n",
       " 648: 'survey',\n",
       " 649: 'decision',\n",
       " 650: 'strategies',\n",
       " 651: 'bias',\n",
       " 652: 'choice',\n",
       " 653: 'improvement',\n",
       " 654: 'achieves',\n",
       " 655: 'suggest',\n",
       " 656: 'smaller',\n",
       " 657: 'sim',\n",
       " 658: 'mapping',\n",
       " 659: 'direction',\n",
       " 660: 'node',\n",
       " 661: 'help',\n",
       " 662: 'detect',\n",
       " 663: 'closed',\n",
       " 664: 'coupled',\n",
       " 665: 'near',\n",
       " 666: 'tests',\n",
       " 667: 'agent',\n",
       " 668: 'codes',\n",
       " 669: 'especially',\n",
       " 670: 'typically',\n",
       " 671: 'extension',\n",
       " 672: 'estimators',\n",
       " 673: 'providing',\n",
       " 674: 'contribution',\n",
       " 675: 'unique',\n",
       " 676: 'train',\n",
       " 677: 'leading',\n",
       " 678: 'mechanisms',\n",
       " 679: 'characteristics',\n",
       " 680: 'having',\n",
       " 681: 'robot',\n",
       " 682: 'reinforcement',\n",
       " 683: 'diffusion',\n",
       " 684: 'experiment',\n",
       " 685: 'dimensions',\n",
       " 686: 'practice',\n",
       " 687: 'concept',\n",
       " 688: 'inthis',\n",
       " 689: 'end',\n",
       " 690: 'issue',\n",
       " 691: 'promising',\n",
       " 692: 'calculations',\n",
       " 693: 'embedding',\n",
       " 694: 'volume',\n",
       " 695: 'content',\n",
       " 696: 'topology',\n",
       " 697: 'world',\n",
       " 698: 'manifold',\n",
       " 699: 'recurrent',\n",
       " 700: 'metrics',\n",
       " 701: 'imaging',\n",
       " 702: 'gives',\n",
       " 703: 'extensive',\n",
       " 704: 'conventional',\n",
       " 705: 'charge',\n",
       " 706: 'far',\n",
       " 707: 'weights',\n",
       " 708: 'implemented',\n",
       " 709: 'challenges',\n",
       " 710: 'algebraic',\n",
       " 711: 'background',\n",
       " 712: 'basic',\n",
       " 713: 'pair',\n",
       " 714: 'aim',\n",
       " 715: 'threshold',\n",
       " 716: 'methodology',\n",
       " 717: 'transitions',\n",
       " 718: 'exhibit',\n",
       " 719: 'formula',\n",
       " 720: 'coefficients',\n",
       " 721: 'mobile',\n",
       " 722: 'despite',\n",
       " 723: 'sensor',\n",
       " 724: 'curves',\n",
       " 725: 'minimal',\n",
       " 726: 'forms',\n",
       " 727: 'programming',\n",
       " 728: 'mode',\n",
       " 729: 'tree',\n",
       " 730: 'external',\n",
       " 731: 'conjecture',\n",
       " 732: 'feedback',\n",
       " 733: 'radio',\n",
       " 734: 'schemes',\n",
       " 735: 'water',\n",
       " 736: 'pattern',\n",
       " 737: 'determined',\n",
       " 738: 'reconstruction',\n",
       " 739: 'thispaper',\n",
       " 740: 'probabilistic',\n",
       " 741: 'disk',\n",
       " 742: 'understand',\n",
       " 743: 'decomposition',\n",
       " 744: 'entropy',\n",
       " 745: 'scaling',\n",
       " 746: 'short',\n",
       " 747: 'actions',\n",
       " 748: 'speech',\n",
       " 749: 'weight',\n",
       " 750: 'partial',\n",
       " 751: 'brain',\n",
       " 752: 'solving',\n",
       " 753: 'path',\n",
       " 754: 'parallel',\n",
       " 755: 'cells',\n",
       " 756: 'idea',\n",
       " 757: 'evaluated',\n",
       " 758: 'sequences',\n",
       " 759: 'showing',\n",
       " 760: 'pairs',\n",
       " 761: 'joint',\n",
       " 762: 'robustness',\n",
       " 763: 'science',\n",
       " 764: 'base',\n",
       " 765: 'importance',\n",
       " 766: 'true',\n",
       " 767: 'unit',\n",
       " 768: 'equilibrium',\n",
       " 769: 'constructed',\n",
       " 770: 'plane',\n",
       " 771: 'overall',\n",
       " 772: 'adaptive',\n",
       " 773: 'atomic',\n",
       " 774: 'variance',\n",
       " 775: 'hidden',\n",
       " 776: 'settings',\n",
       " 777: 'description',\n",
       " 778: 'lie',\n",
       " 779: 'massive',\n",
       " 780: 'identified',\n",
       " 781: 'consists',\n",
       " 782: 'sense',\n",
       " 783: 'ones',\n",
       " 784: 'likelihood',\n",
       " 785: 'applying',\n",
       " 786: 'curve',\n",
       " 787: 'combined',\n",
       " 788: 'simulated',\n",
       " 789: 'sensitivity',\n",
       " 790: 'architectures',\n",
       " 791: 'formulation',\n",
       " 792: 'flows',\n",
       " 793: 'according',\n",
       " 794: 'forthe',\n",
       " 795: 'considering',\n",
       " 796: 'scenario',\n",
       " 797: 'program',\n",
       " 798: 'period',\n",
       " 799: 'grid',\n",
       " 800: 'inputs',\n",
       " 801: 'stellar',\n",
       " 802: 'cnn',\n",
       " 803: 'exponential',\n",
       " 804: 'pressure',\n",
       " 805: 'analytical',\n",
       " 806: 'showthat',\n",
       " 807: 'category',\n",
       " 808: 'solar',\n",
       " 809: 'proved',\n",
       " 810: 'technology',\n",
       " 811: 'semantic',\n",
       " 812: 'agreement',\n",
       " 813: 'symmetric',\n",
       " 814: 'includes',\n",
       " 815: 'infinite',\n",
       " 816: 'descent',\n",
       " 817: 'curvature',\n",
       " 818: 'lack',\n",
       " 819: 'depth',\n",
       " 820: 'games',\n",
       " 821: 'difference',\n",
       " 822: 'depending',\n",
       " 823: 'material',\n",
       " 824: 'cell',\n",
       " 825: 'view',\n",
       " 826: 'computed',\n",
       " 827: 'review',\n",
       " 828: 'findings',\n",
       " 829: 'allowing',\n",
       " 830: 'labels',\n",
       " 831: 'traffic',\n",
       " 832: 'cloud',\n",
       " 833: 'galaxy',\n",
       " 834: 'environments',\n",
       " 835: 'typical',\n",
       " 836: 'increases',\n",
       " 837: 'tested',\n",
       " 838: 'powerful',\n",
       " 839: 'indicate',\n",
       " 840: 'causal',\n",
       " 841: 'interface',\n",
       " 842: 'thatthe',\n",
       " 843: 'embeddings',\n",
       " 844: 'beam',\n",
       " 845: 'array',\n",
       " 846: 'particularly',\n",
       " 847: 'superconducting',\n",
       " 848: 'usually',\n",
       " 849: 'building',\n",
       " 850: 'relations',\n",
       " 851: 'hypothesis',\n",
       " 852: 'security',\n",
       " 853: 'media',\n",
       " 854: 'aspects',\n",
       " 855: 'planning',\n",
       " 856: 'variational',\n",
       " 857: 'invariant',\n",
       " 858: 'strength',\n",
       " 859: 'highdimensional',\n",
       " 860: 'estimating',\n",
       " 861: 'surfaces',\n",
       " 862: 'observation',\n",
       " 863: 'differences',\n",
       " 864: 'characterize',\n",
       " 865: 'video',\n",
       " 866: 'instances',\n",
       " 867: 'weighted',\n",
       " 868: 'aims',\n",
       " 869: 'precision',\n",
       " 870: 'generating',\n",
       " 871: 'matching',\n",
       " 872: 'estimated',\n",
       " 873: 'twodimensional',\n",
       " 874: 'appropriate',\n",
       " 875: 'momentum',\n",
       " 876: 'distinct',\n",
       " 877: 'fraction',\n",
       " 878: 'capacity',\n",
       " 879: 'explain',\n",
       " 880: 'andthe',\n",
       " 881: 'broad',\n",
       " 882: 'issues',\n",
       " 883: 'detailed',\n",
       " 884: 'errors',\n",
       " 885: 'exist',\n",
       " 886: 'operations',\n",
       " 887: 'past',\n",
       " 888: 'contains',\n",
       " 889: 'sizes',\n",
       " 890: 'reveal',\n",
       " 891: 'constraint',\n",
       " 892: 'mathematical',\n",
       " 893: 'vectors',\n",
       " 894: 'correlations',\n",
       " 895: 'likely',\n",
       " 896: 'periodic',\n",
       " 897: 'atoms',\n",
       " 898: 'behaviour',\n",
       " 899: 'subject',\n",
       " 900: 'flux',\n",
       " 901: 'link',\n",
       " 902: 'principle',\n",
       " 903: 'filter',\n",
       " 904: 'remains',\n",
       " 905: 'exists',\n",
       " 906: 'rules',\n",
       " 907: 'baseline',\n",
       " 908: 'classifier',\n",
       " 909: 'static',\n",
       " 910: 'combining',\n",
       " 911: 'capable',\n",
       " 912: 'expansion',\n",
       " 913: 'similarity',\n",
       " 914: 'logic',\n",
       " 915: 'chemical',\n",
       " 916: 'propagation',\n",
       " 917: 'vision',\n",
       " 918: 'identification',\n",
       " 919: 'questions',\n",
       " 920: 'generic',\n",
       " 921: 'robots',\n",
       " 922: 'fluctuations',\n",
       " 923: 'position',\n",
       " 924: 'liquid',\n",
       " 925: 'reference',\n",
       " 926: 'motivated',\n",
       " 927: 'conditional',\n",
       " 928: 'uniform',\n",
       " 929: 'correlated',\n",
       " 930: 'policies',\n",
       " 931: 'characterization',\n",
       " 932: 'improves',\n",
       " 933: 'resources',\n",
       " 934: 'inverse',\n",
       " 935: 'event',\n",
       " 936: 'easily',\n",
       " 937: 'simultaneously',\n",
       " 938: 'yields',\n",
       " 939: 'negative',\n",
       " 940: 'missing',\n",
       " 941: 'driven',\n",
       " 942: 'heat',\n",
       " 943: 'fluid',\n",
       " 944: 'sensors',\n",
       " 945: 'limits',\n",
       " 946: 'advantage',\n",
       " 947: 'enable',\n",
       " 948: 'variations',\n",
       " 949: 'law',\n",
       " 950: 'segmentation',\n",
       " 951: 'needed',\n",
       " 952: 'effectively',\n",
       " 953: 'manifolds',\n",
       " 954: 'unsupervised',\n",
       " 955: 'crucial',\n",
       " 956: 'realtime',\n",
       " 957: 'posterior',\n",
       " 958: 'orders',\n",
       " 959: 'alpha',\n",
       " 960: 'purpose',\n",
       " 961: 'regular',\n",
       " 962: 'instance',\n",
       " 963: 'success',\n",
       " 964: 'treatment',\n",
       " 965: 'experimentally',\n",
       " 966: 'predictive',\n",
       " 967: 'phenomena',\n",
       " 968: 'represent',\n",
       " 969: 'needs',\n",
       " 970: 'market',\n",
       " 971: 'wepropose',\n",
       " 972: 'generally',\n",
       " 973: 'characteristic',\n",
       " 974: 'nontrivial',\n",
       " 975: 'relationship',\n",
       " 976: 'comparable',\n",
       " 977: 'guarantees',\n",
       " 978: 'explicitly',\n",
       " 979: 'numerically',\n",
       " 980: 'automatically',\n",
       " 981: 'words',\n",
       " 982: 'build',\n",
       " 983: 'realistic',\n",
       " 984: 'bulk',\n",
       " 985: 'square',\n",
       " 986: 'transmission',\n",
       " 987: 'lines',\n",
       " 988: 'generalize',\n",
       " 989: 'dependent',\n",
       " 990: 'produced',\n",
       " 991: 'yield',\n",
       " 992: 'variation',\n",
       " 993: 'depend',\n",
       " 994: 'attacks',\n",
       " 995: 'proposes',\n",
       " 996: 'rely',\n",
       " 997: 'polynomials',\n",
       " 998: 'quantitative',\n",
       " 999: 'singular',\n",
       " ...}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word = {}\n",
    "keys = []\n",
    "for i in range(len(dtm1)):\n",
    "  j = dtm1.index.get_loc(dtm1.index[i])\n",
    "  keys.append(j)\n",
    "\n",
    "for key, val in zip(keys, dtm1.index):\n",
    "  id2word[key] = val\n",
    "\n",
    "id2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.016*\"data\" + 0.011*\"model\" + 0.009*\"learning\" + 0.008*\"using\" + 0.008*\"network\" + 0.007*\"models\" + 0.007*\"paper\" + 0.007*\"approach\" + 0.007*\"based\" + 0.007*\"method\"'),\n",
       " (1,\n",
       "  '0.007*\"study\" + 0.007*\"model\" + 0.007*\"results\" + 0.006*\"problem\" + 0.005*\"theory\" + 0.005*\"function\" + 0.005*\"paper\" + 0.005*\"field\" + 0.005*\"number\" + 0.005*\"using\"')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=2, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.012*\"problem\" + 0.009*\"paper\" + 0.008*\"number\" + 0.008*\"function\" + 0.008*\"prove\" + 0.007*\"results\" + 0.007*\"space\" + 0.007*\"set\" + 0.007*\"study\" + 0.006*\"case\"'),\n",
       " (1,\n",
       "  '0.011*\"model\" + 0.009*\"energy\" + 0.007*\"phase\" + 0.007*\"field\" + 0.007*\"using\" + 0.007*\"quantum\" + 0.006*\"magnetic\" + 0.006*\"study\" + 0.006*\"results\" + 0.005*\"dynamics\"'),\n",
       " (2,\n",
       "  '0.017*\"data\" + 0.012*\"model\" + 0.011*\"learning\" + 0.009*\"network\" + 0.008*\"models\" + 0.008*\"using\" + 0.008*\"approach\" + 0.008*\"paper\" + 0.007*\"based\" + 0.007*\"method\"')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=3, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.015*\"data\" + 0.013*\"learning\" + 0.011*\"network\" + 0.010*\"model\" + 0.008*\"networks\" + 0.008*\"paper\" + 0.008*\"approach\" + 0.008*\"using\" + 0.007*\"based\" + 0.007*\"models\"'),\n",
       " (1,\n",
       "  '0.018*\"data\" + 0.016*\"model\" + 0.009*\"models\" + 0.009*\"distribution\" + 0.008*\"using\" + 0.008*\"method\" + 0.007*\"results\" + 0.006*\"used\" + 0.006*\"analysis\" + 0.006*\"estimation\"'),\n",
       " (2,\n",
       "  '0.011*\"energy\" + 0.011*\"model\" + 0.010*\"phase\" + 0.010*\"quantum\" + 0.009*\"field\" + 0.008*\"dynamics\" + 0.008*\"magnetic\" + 0.007*\"state\" + 0.007*\"study\" + 0.006*\"states\"'),\n",
       " (3,\n",
       "  '0.015*\"problem\" + 0.010*\"paper\" + 0.009*\"prove\" + 0.008*\"number\" + 0.008*\"set\" + 0.007*\"function\" + 0.007*\"space\" + 0.007*\"results\" + 0.007*\"algorithm\" + 0.007*\"functions\"')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "ldana = models.LdaModel(corpus=corpus, num_topics=4, id2word=id2word, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.011*\"prove\" + 0.010*\"space\" + 0.010*\"paper\" + 0.009*\"graph\" + 0.008*\"study\" + 0.008*\"theory\" + 0.008*\"set\" + 0.008*\"group\" + 0.008*\"result\" + 0.008*\"results\"'),\n",
       " (1,\n",
       "  '0.010*\"model\" + 0.009*\"energy\" + 0.008*\"phase\" + 0.007*\"using\" + 0.007*\"field\" + 0.006*\"quantum\" + 0.006*\"magnetic\" + 0.006*\"results\" + 0.006*\"study\" + 0.005*\"state\"'),\n",
       " (2,\n",
       "  '0.015*\"algorithm\" + 0.014*\"problem\" + 0.013*\"method\" + 0.012*\"model\" + 0.009*\"time\" + 0.008*\"proposed\" + 0.008*\"paper\" + 0.007*\"based\" + 0.007*\"function\" + 0.007*\"methods\"'),\n",
       " (3,\n",
       "  '0.018*\"data\" + 0.014*\"learning\" + 0.012*\"network\" + 0.010*\"model\" + 0.010*\"networks\" + 0.008*\"using\" + 0.008*\"paper\" + 0.007*\"models\" + 0.007*\"neural\" + 0.007*\"approach\"')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ldana = models.LdaModel(corpus=corpus, num_topics=4, id2word=id2word, passes=80)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to pull out nouns from a string of text\n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "def nouns(text):\n",
    "    '''Given a string of text, tokenize the text and pull out only the nouns.'''\n",
    "    is_noun = lambda pos: pos[:2] == 'NN'\n",
    "    tokenized = word_tokenize(text)\n",
    "    all_nouns = [word for (word, pos) in pos_tag(tokenized) if is_noun(pos)] \n",
    "    return ' '.join(all_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABSTRACT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>understandings gammapoisson gap model matrix f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>meteorites minerals system asteroids different...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>frame aggregation mechanism frames transmissio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>way clusters terms age chemicalcomposition pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>protocol secrecy taskone strategies goal secur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8984</th>\n",
       "      <td>problem support matrix multiplication gemm ope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8985</th>\n",
       "      <td>theory decision blackwell policyis policy disc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8986</th>\n",
       "      <td>genevis tool data sets differentdisciplines fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8987</th>\n",
       "      <td>paper effect speed cameras road traffic doubly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8988</th>\n",
       "      <td>vertices edges grid graph gvedgeqslant integer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8989 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               ABSTRACT\n",
       "0     understandings gammapoisson gap model matrix f...\n",
       "1     meteorites minerals system asteroids different...\n",
       "2     frame aggregation mechanism frames transmissio...\n",
       "3     way clusters terms age chemicalcomposition pro...\n",
       "4     protocol secrecy taskone strategies goal secur...\n",
       "...                                                 ...\n",
       "8984  problem support matrix multiplication gemm ope...\n",
       "8985  theory decision blackwell policyis policy disc...\n",
       "8986  genevis tool data sets differentdisciplines fi...\n",
       "8987  paper effect speed cameras road traffic doubly...\n",
       "8988  vertices edges grid graph gvedgeqslant integer...\n",
       "\n",
       "[8989 rows x 1 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "data_nouns = pd.DataFrame(data.ABSTRACT.apply(nouns))\n",
    "data_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\PYTHON39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>__</th>\n",
       "      <th>__maser</th>\n",
       "      <th>_au</th>\n",
       "      <th>_f_</th>\n",
       "      <th>_f_left</th>\n",
       "      <th>_i</th>\n",
       "      <th>_ia</th>\n",
       "      <th>_ide</th>\n",
       "      <th>_isubgroup</th>\n",
       "      <th>_knot</th>\n",
       "      <th>...</th>\n",
       "      <th>ésik</th>\n",
       "      <th>été</th>\n",
       "      <th>être</th>\n",
       "      <th>öffentliches</th>\n",
       "      <th>özgün</th>\n",
       "      <th>übergravity</th>\n",
       "      <th>ünlü</th>\n",
       "      <th>čech</th>\n",
       "      <th>świątkowskia</th>\n",
       "      <th>ševera</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8984</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8985</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8986</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8987</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8988</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8989 rows × 71117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      __  __maser  _au  _f_  _f_left  _i  _ia  _ide  _isubgroup  _knot  ...  \\\n",
       "0      0        0    0    0        0   0    0     0           0      0  ...   \n",
       "1      0        0    0    0        0   0    0     0           0      0  ...   \n",
       "2      0        0    0    0        0   0    0     0           0      0  ...   \n",
       "3      0        0    0    0        0   0    0     0           0      0  ...   \n",
       "4      0        0    0    0        0   0    0     0           0      0  ...   \n",
       "...   ..      ...  ...  ...      ...  ..  ...   ...         ...    ...  ...   \n",
       "8984   0        0    0    0        0   0    0     0           0      0  ...   \n",
       "8985   0        0    0    0        0   0    0     0           0      0  ...   \n",
       "8986   0        0    0    0        0   0    0     0           0      0  ...   \n",
       "8987   0        0    0    0        0   0    0     0           0      0  ...   \n",
       "8988   0        0    0    0        0   0    0     0           0      0  ...   \n",
       "\n",
       "      ésik  été  être  öffentliches  özgün  übergravity  ünlü  čech  \\\n",
       "0        0    0     0             0      0            0     0     0   \n",
       "1        0    0     0             0      0            0     0     0   \n",
       "2        0    0     0             0      0            0     0     0   \n",
       "3        0    0     0             0      0            0     0     0   \n",
       "4        0    0     0             0      0            0     0     0   \n",
       "...    ...  ...   ...           ...    ...          ...   ...   ...   \n",
       "8984     0    0     0             0      0            0     0     0   \n",
       "8985     0    0     0             0      0            0     0     0   \n",
       "8986     0    0     0             0      0            0     0     0   \n",
       "8987     0    0     0             0      0            0     0     0   \n",
       "8988     0    0     0             0      0            0     0     0   \n",
       "\n",
       "      świątkowskia  ševera  \n",
       "0                0       0  \n",
       "1                0       0  \n",
       "2                0       0  \n",
       "3                0       0  \n",
       "4                0       0  \n",
       "...            ...     ...  \n",
       "8984             0       0  \n",
       "8985             0       0  \n",
       "8986             0       0  \n",
       "8987             0       0  \n",
       "8988             0       0  \n",
       "\n",
       "[8989 rows x 71117 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# add_stop_words = ['aa','flightled','jetblue','need','im','dont','just','guys']\n",
    "# stop_words = text.ENGLISH_STOP_WORDS.union(add_stop_words)\n",
    "\n",
    "# Recreate a document-term matrix with only nouns\n",
    "cvn = CountVectorizer()\n",
    "data_cvn = cvn.fit_transform(data_nouns.ABSTRACT)\n",
    "data_dtmn = pd.DataFrame(data_cvn.toarray(), columns=cvn.get_feature_names())\n",
    "data_dtmn.index = data_nouns.index\n",
    "data_dtmn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>8979</th>\n",
       "      <th>8980</th>\n",
       "      <th>8981</th>\n",
       "      <th>8982</th>\n",
       "      <th>8983</th>\n",
       "      <th>8984</th>\n",
       "      <th>8985</th>\n",
       "      <th>8986</th>\n",
       "      <th>8987</th>\n",
       "      <th>8988</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>__</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>__maser</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_au</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_f_</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_f_left</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_i</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_ia</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_ide</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_isubgroup</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_knot</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 8989 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0     1     2     3     4     5     6     7     8     9     ...  \\\n",
       "__             0     0     0     0     0     0     0     0     0     0  ...   \n",
       "__maser        0     0     0     0     0     0     0     0     0     0  ...   \n",
       "_au            0     0     0     0     0     0     0     0     0     0  ...   \n",
       "_f_            0     0     0     0     0     0     0     0     0     0  ...   \n",
       "_f_left        0     0     0     0     0     0     0     0     0     0  ...   \n",
       "_i             0     0     0     0     0     0     0     0     0     0  ...   \n",
       "_ia            0     0     0     0     0     0     0     0     0     0  ...   \n",
       "_ide           0     0     0     0     0     0     0     0     0     0  ...   \n",
       "_isubgroup     0     0     0     0     0     0     0     0     0     0  ...   \n",
       "_knot          0     0     0     0     0     0     0     0     0     0  ...   \n",
       "\n",
       "            8979  8980  8981  8982  8983  8984  8985  8986  8987  8988  \n",
       "__             0     0     0     0     0     0     0     0     0     0  \n",
       "__maser        0     0     0     0     0     0     0     0     0     0  \n",
       "_au            0     0     0     0     0     0     0     0     0     0  \n",
       "_f_            0     0     0     0     0     0     0     0     0     0  \n",
       "_f_left        0     0     0     0     0     0     0     0     0     0  \n",
       "_i             0     0     0     0     0     0     0     0     0     0  \n",
       "_ia            0     0     0     0     0     0     0     0     0     0  \n",
       "_ide           0     0     0     0     0     0     0     0     0     0  \n",
       "_isubgroup     0     0     0     0     0     0     0     0     0     0  \n",
       "_knot          0     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[10 rows x 8989 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdm3 = data_dtmn.transpose()\n",
    "tdm3.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusn = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(tdm3))\n",
    "\n",
    "# Create the vocabulary dictionary\n",
    "id2wordn = dict((v, k) for k, v in cvn.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.013*\"data\" + 0.010*\"model\" + 0.008*\"paper\" + 0.007*\"network\" + 0.007*\"problem\" + 0.006*\"models\" + 0.006*\"method\" + 0.006*\"approach\" + 0.006*\"results\" + 0.006*\"methods\"'),\n",
       " (1,\n",
       "  '0.005*\"model\" + 0.005*\"results\" + 0.005*\"field\" + 0.004*\"system\" + 0.004*\"energy\" + 0.004*\"theory\" + 0.004*\"space\" + 0.003*\"phase\" + 0.003*\"paper\" + 0.003*\"properties\"')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldan = models.LdaModel(corpus=corpusn, num_topics=2, id2word=id2wordn, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.006*\"theory\" + 0.005*\"paper\" + 0.005*\"space\" + 0.005*\"results\" + 0.004*\"number\" + 0.004*\"problem\" + 0.004*\"result\" + 0.004*\"case\" + 0.004*\"group\" + 0.004*\"quantum\"'),\n",
       " (1,\n",
       "  '0.014*\"data\" + 0.010*\"model\" + 0.008*\"paper\" + 0.008*\"problem\" + 0.008*\"network\" + 0.007*\"method\" + 0.007*\"models\" + 0.007*\"approach\" + 0.006*\"results\" + 0.006*\"methods\"'),\n",
       " (2,\n",
       "  '0.007*\"model\" + 0.006*\"energy\" + 0.005*\"field\" + 0.004*\"system\" + 0.004*\"results\" + 0.004*\"data\" + 0.004*\"mass\" + 0.003*\"time\" + 0.003*\"dynamics\" + 0.003*\"temperature\"')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldan = models.LdaModel(corpus=corpusn, num_topics=3, id2word=id2wordn, passes=10)\n",
    "ldan.print_topics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.008*\"paper\" + 0.008*\"problem\" + 0.007*\"space\" + 0.006*\"number\" + 0.006*\"results\" + 0.005*\"case\" + 0.005*\"result\" + 0.005*\"function\" + 0.005*\"theory\" + 0.005*\"group\"'),\n",
       " (1,\n",
       "  '0.016*\"data\" + 0.010*\"model\" + 0.009*\"paper\" + 0.009*\"network\" + 0.008*\"problem\" + 0.007*\"approach\" + 0.007*\"method\" + 0.007*\"networks\" + 0.007*\"models\" + 0.007*\"methods\"'),\n",
       " (2,\n",
       "  '0.006*\"energy\" + 0.006*\"data\" + 0.006*\"mass\" + 0.004*\"model\" + 0.004*\"results\" + 0.004*\"observations\" + 0.003*\"system\" + 0.003*\"field\" + 0.003*\"galaxies\" + 0.003*\"time\"'),\n",
       " (3,\n",
       "  '0.012*\"model\" + 0.006*\"phase\" + 0.006*\"state\" + 0.006*\"dynamics\" + 0.005*\"systems\" + 0.005*\"system\" + 0.005*\"results\" + 0.005*\"states\" + 0.005*\"models\" + 0.005*\"properties\"')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldan = models.LdaModel(corpus=corpusn, num_topics=4, id2word=id2wordn, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nouns_adj(text):\n",
    "    '''Given a string of text, tokenize the text and pull out only the nouns and adjectives.'''\n",
    "    is_noun_adj = lambda pos: pos[:2] == 'NN' or pos[:2] == 'JJ'\n",
    "    tokenized = word_tokenize(text)\n",
    "    nouns_adj = [word for (word, pos) in pos_tag(tokenized) if is_noun_adj(pos)] \n",
    "    return ' '.join(nouns_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABSTRACT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>novel understandings gammapoisson gap model ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>meteorites minerals solar system asteroids dif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>frame aggregation mechanism multiple frames as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>milky way open clusters diverse terms age chem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cryptographic protocol correct secrecy hard ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8984</th>\n",
       "      <td>problem mixeddatatype support thegeneral matri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8985</th>\n",
       "      <td>theory markov decision blackwell optimal polic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8986</th>\n",
       "      <td>genevis webbased tool complementary data sets ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8987</th>\n",
       "      <td>paper effect speed cameras road traffic approx...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8988</th>\n",
       "      <td>vertices edges ddimensional grid graph gvedgeq...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8989 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               ABSTRACT\n",
       "0     novel understandings gammapoisson gap model ap...\n",
       "1     meteorites minerals solar system asteroids dif...\n",
       "2     frame aggregation mechanism multiple frames as...\n",
       "3     milky way open clusters diverse terms age chem...\n",
       "4     cryptographic protocol correct secrecy hard ta...\n",
       "...                                                 ...\n",
       "8984  problem mixeddatatype support thegeneral matri...\n",
       "8985  theory markov decision blackwell optimal polic...\n",
       "8986  genevis webbased tool complementary data sets ...\n",
       "8987  paper effect speed cameras road traffic approx...\n",
       "8988  vertices edges ddimensional grid graph gvedgeq...\n",
       "\n",
       "[8989 rows x 1 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_nouns_adj = pd.DataFrame(data.ABSTRACT.apply(nouns_adj))\n",
    "data_nouns_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\PYTHON39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "df_cv = cv.fit_transform(data_nouns_adj.ABSTRACT)\n",
    "dt = pd.DataFrame(df_cv.toarray()).iloc[:len(data)]  \n",
    "dt.columns = cv.get_feature_names()\n",
    "dt.index = data_nouns_adj.index\n",
    "document_term_matrix = dt.T\n",
    "document_term_matrix.columns = ['Text '+str(i+1) for i in range(len(data_nouns_adj))]\n",
    "document_term_matrix['total_count'] = document_term_matrix.sum(axis=1)\n",
    "\n",
    "document_term_matrix = document_term_matrix.sort_values(by ='total_count',ascending=False)[:2000] \n",
    "\n",
    "# print(document_term_matrix.drop(columns=['total_count']).head(10))\n",
    "most_common = document_term_matrix.index\n",
    "document_term_matrix = document_term_matrix.drop(columns=['total_count'])\n",
    "tdm4 = pd.DataFrame(document_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusna = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(tdm4))\n",
    "\n",
    "# Create the vocabulary dictionary\n",
    "id2wordna = dict((v, k) for k, v in cv.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.005*\"acc\" + 0.001*\"adultsubjects\" + 0.001*\"adversarialquantum\" + 0.000*\"achievestateoftheart\" + 0.000*\"acidulation\" + 0.000*\"advancedligo\" + 0.000*\"agoaldirected\" + 0.000*\"acorrupted\" + 0.000*\"accompanying\" + 0.000*\"acentral\"'),\n",
       " (1,\n",
       "  '0.010*\"__\" + 0.009*\"__maser\" + 0.007*\"_au\" + 0.007*\"_dcal\" + 0.006*\"_f_\" + 0.005*\"_f_left\" + 0.005*\"_i\" + 0.005*\"_ia\" + 0.005*\"_isubgroup\" + 0.005*\"_ide\"')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldana = models.LdaModel(corpus=corpusna, num_topics=2, id2word=id2wordna, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.006*\"__maser\" + 0.006*\"_dcal\" + 0.006*\"a_and\" + 0.005*\"a_b\" + 0.005*\"a_breo_asr\" + 0.005*\"a_rm\" + 0.005*\"a_tb_t\" + 0.004*\"_s\" + 0.004*\"_ia\" + 0.004*\"a_b_ldotsa_kb_kc\"'),\n",
       " (1,\n",
       "  '0.000*\"againstadversarial\" + 0.000*\"adaptivevariant\" + 0.000*\"actuarial\" + 0.000*\"ahotspotunaware\" + 0.000*\"aggregated\" + 0.000*\"adiscriminator\" + 0.000*\"adaptiveamsdu\" + 0.000*\"agradient\" + 0.000*\"aforementionedassumption\" + 0.000*\"actionable\"'),\n",
       " (2,\n",
       "  '0.015*\"__\" + 0.011*\"__maser\" + 0.009*\"_au\" + 0.008*\"_f_\" + 0.008*\"_ide\" + 0.007*\"_i\" + 0.007*\"_f_left\" + 0.007*\"_isubgroup\" + 0.007*\"_dcal\" + 0.007*\"_m_oplus\"')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldana = models.LdaModel(corpus=corpusna, num_topics=3, id2word=id2wordna, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.017*\"__\" + 0.012*\"__maser\" + 0.009*\"_ide\" + 0.008*\"_au\" + 0.008*\"_i\" + 0.008*\"_isubgroup\" + 0.008*\"_f_left\" + 0.007*\"_dcal\" + 0.007*\"_mathrmrig\" + 0.007*\"_n\"'),\n",
       " (1,\n",
       "  '0.008*\"a_b\" + 0.008*\"__maser\" + 0.008*\"a_rm\" + 0.007*\"a_and\" + 0.007*\"aapproximation\" + 0.007*\"a_tb_t\" + 0.005*\"a_b_\" + 0.005*\"abeliansquares\" + 0.005*\"abipartite\" + 0.005*\"abiotic\"'),\n",
       " (2,\n",
       "  '0.000*\"advective\" + 0.000*\"aggregated\" + 0.000*\"akahler\" + 0.000*\"acyberagent\" + 0.000*\"ag_biterminated\" + 0.000*\"acousticsensors\" + 0.000*\"aeronautics\" + 0.000*\"achievesorders\" + 0.000*\"accumulationlayer\" + 0.000*\"acquisitionand\"'),\n",
       " (3,\n",
       "  '0.011*\"_f_\" + 0.008*\"_au\" + 0.007*\"_poperatornamespecmathbbf_pu\" + 0.007*\"_linfty\" + 0.007*\"_dcal\" + 0.007*\"_s\" + 0.006*\"a_a_dots\" + 0.006*\"a_breo_asr\" + 0.006*\"a_pclasses\" + 0.006*\"a_inftystructures\"')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldana = models.LdaModel(corpus=corpusna, num_topics=4, id2word=id2wordna, passes=10)\n",
    "ldana.print_topics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9e9701399897d18cead94548cd7917f628a445e8c160dff455900c56a0c5bc6d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
